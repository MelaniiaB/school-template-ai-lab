<!DOCTYPE html>
<html lang="uk">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Система розпізнавання емоцій</title>
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <header>
        <h1>"SafeMood Bot" - емпатичний AI-чатбот з камерою</h1>
    </header>

    <section id="project-overview">
        <h2>Огляд проєкту</h2>
        <p>Цей проєкт спрямований на створення Telegram-бота, який зможе розпізнавати емоції людей у реальному часі використовуючи комп'ютерний зір та глибоке навчання, спілкуватися з користувачами та давати їм різні корисні поради.</p>
        
        <h3>Мета проєкту:</h3>
        <p>Створити інтерактивного Telegram-бота, який за допомогою штучного інтелекту аналізує емоційний стан користувача через камеру та адаптує спілкування до його настрою, щоб надавати психологічну підтримку, підвищувати емоційну обізнаність і запобігати розвитку стресових станів та депресії. </p>
        
        <h3>Основні завдання:</h3>
        <ul>
            <li> Створення Telegram-бота</li>
            <li>Виділення аудіо з відео</li>
            <li>Розпізнавання мову з аудіо</li>
            <li>Розбивання відео на кадри</li>
            <li>Аналізування емоції на обличчі</li>
            <li>Оброблення тексту користувача</li>
            <li>Формування відповіді бота</li>
            <li>Забезпечення приватності</li>
            <li>Тестування бота на різних сценаріях спілкування</li>
        </ul>
    </section>

    <section id="technical-details">
        <h2>Технічна реалізація</h2>
        <h3>Використані технології:</h3>
        <ul>
            <li>Python 3.9 з бібліотеками TensorFlow та OpenCV</li>
            <li>JavaScript для взаємодії з веб-камерою</li>
            <li>HTML5/CSS3 для інтерфейсу користувача</li>
            <li>Flask для серверної частини</li>
        </ul>
        
        <h3>Інноваційні аспекти:</h3>
        <ul>
            <li>Власна архітектура нейронної мережі для класифікації емоцій</li>
            <li>Оптимізований алгоритм обробки відеопотоку</li>
            <li>Адаптивна система освітлення для покращення точності</li>
        </ul>
    </section>

    <section id="data-sources">
        <h2>Використані дані</h2>
        <ul>
            <li>FER-2013 датасет для тренування моделі (35,887 зображень)</li>
            <li>CK+ dataset для валідації (593 послідовності зображень)</li>
            <li>Власний набір даних для тестування (1,000 зображень)</li>
        </ul>
        <p>Всі дані використовуються з дотриманням ліцензій та правил академічної доброчесності.</p>
    </section>

    <section id="results">
        <h2>Результати</h2>
        <ul>
            <li>Точність розпізнавання емоцій: 89%</li>
            <li>Швидкість обробки: 30 кадрів/сек</li>
            <li>Підтримка 7 базових емоцій</li>
        </ul>
    </section>

    <section id="demo">
        <h2>Демонстрація</h2>
        <div id="camera-container">
            <video id="video" width="640" height="480" autoplay></video>
            <canvas id="canvas" width="640" height="480"></canvas>
        </div>
        <button id="start-camera">Запустити демо</button>
    </section>

    <footer>
        <p>&copy; 2024 Тарас Шевченко | <a href="../index.html">Назад до проєктів</a></p>
    </footer>
</body>
</html>
